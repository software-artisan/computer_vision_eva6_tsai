{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_5_8k_parameters_ver2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/software-artisan/computer_vision_eva6_tsai/blob/main/session_5_code_drill_down/assignment_5_8k_parameters_ver2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpPYe-KP0ESK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from collections import OrderedDict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        dropout=0.05\n",
        " \n",
        "        ####### \n",
        "        # Convolution Block #1\n",
        "        #########\n",
        "        self.conv1_1_3_3_8_p = nn.Sequential(OrderedDict([\n",
        "            ('conv1_1_3_3_8_p', nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=1, bias=False)),\n",
        "            ('relu', nn.ReLU()),\n",
        "            ('batchNorm2d', nn.BatchNorm2d(num_features=8)),\n",
        "            ('dropOut2d', nn.Dropout2d(p=dropout))\n",
        "          ])\n",
        "        ) # Input=28, Output=28, rf=3\n",
        "\n",
        "        self.conv2_8_3_3_8_p = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=8),\n",
        "            nn.Dropout2d(p=dropout)\n",
        "        ) # Input=28, Output=28, rf=5\n",
        " \n",
        "        self.conv3_8_3_3_8_p = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=8),\n",
        "            nn.Dropout2d(p=dropout) \n",
        "        ) # Input=28, Output=28, rf=10\n",
        " \n",
        "        ####### \n",
        "        # Transition Block #1\n",
        "        #########\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2) # Input=28, Output=14, rf=6\n",
        " \n",
        "        self.conv4_8_1_1_16 = nn.Sequential(\n",
        "            #nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=0, bias=False),\n",
        "            nn.Conv2d(in_channels=8, out_channels=12, kernel_size=1, padding=0, bias=False),\n",
        "        ) # Input=14, Output=14, rf=32\n",
        " \n",
        "        ####### \n",
        "        # Convolution Block #2\n",
        "        #########\n",
        "        self.conv5_12_3_3_12 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=12),\n",
        "            nn.Dropout2d(p=dropout)\n",
        "        ) # Input=14, Output=12, rf=14\n",
        " \n",
        "        self.conv6_12_3_3_12 = nn.Sequential(\n",
        "            #nn.Conv2d(in_channels=14, out_channels=14, kernel_size=3, padding=0, bias=False),\n",
        "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=12),\n",
        "            nn.Dropout2d(p=dropout) # Input=12, Output=10, rf=24\n",
        "        )\n",
        "        \n",
        "        self.conv7_12_3_3_12 = nn.Sequential(\n",
        "            #nn.Conv2d(in_channels=14, out_channels=14, kernel_size=3, padding=0, bias=False),\n",
        "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=12),\n",
        "            nn.Dropout2d(p=dropout) # Input=10, Output=8, rf=24\n",
        "        )\n",
        "        \n",
        "        self.conv8_12_3_3_12 = nn.Sequential(\n",
        "            #nn.Conv2d(in_channels=14, out_channels=14, kernel_size=3, padding=0, bias=False),\n",
        "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=12),\n",
        "            nn.Dropout2d(p=dropout) \n",
        "        ) # Input=8, Output=6, rf=24\n",
        "\n",
        "        self.conv9_12_3_3_12 = nn.Sequential(\n",
        "            #nn.Conv2d(in_channels=14, out_channels=14, kernel_size=3, padding=0, bias=False),\n",
        "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=12),\n",
        "            nn.Dropout2d(p=dropout) \n",
        "        ) # Input=6, Output=4, rf=24\n",
        "        \n",
        "        self.maxpool2= nn.MaxPool2d(kernel_size=2, stride=2) # Input=4, Output=2, rf=16\n",
        " \n",
        "        ####### \n",
        "        # Output Block\n",
        "        #########\n",
        "        # global average pool before 1x1 to reduce computation\n",
        "        self.global_avgpool = nn.AdaptiveAvgPool2d(output_size=1)  # Input=5, Output=1, rf=40\n",
        " \n",
        "        self.conv10_16_1_1_10 = nn.Sequential(\n",
        "            #nn.Conv2d(in_channels=14, out_channels=10, kernel_size=3, padding=0, bias=False),\n",
        "            nn.Conv2d(in_channels=12, out_channels=10, kernel_size=1, padding=0, bias=False),\n",
        "        ) # Input=1, Output=1, rf=32\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #####\n",
        "        # conv block #1\n",
        "        ########\n",
        "        x = self.conv1_1_3_3_8_p(x)\n",
        "        x = self.conv2_8_3_3_8_p(x)\n",
        "        x = self.conv3_8_3_3_8_p(x)\n",
        " \n",
        "        #####\n",
        "        # Transitioni block #1\n",
        "        ########\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv4_8_1_1_16(x)\n",
        " \n",
        "        #####\n",
        "        # conv block #2\n",
        "        ########\n",
        "        x = self.conv5_12_3_3_12(x)\n",
        "        x = self.conv6_12_3_3_12(x)\n",
        "        x = self.conv7_12_3_3_12(x)\n",
        "        x = self.conv8_12_3_3_12(x)\n",
        "        x = self.conv9_12_3_3_12(x)\n",
        "\n",
        "        #######\n",
        "        # Transition block #2\n",
        "        #######\n",
        "        x = self.maxpool2(x)\n",
        " \n",
        "        #####\n",
        "        # output block\n",
        "        ########\n",
        "        x = self.global_avgpool(x)        \n",
        "        x = self.conv10_16_1_1_10(x)\n",
        "               \n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdydjYTZFyi3",
        "outputId": "d4b2c074-baa6-42b7-d52b-80b8b720b31c"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              72\n",
            "              ReLU-2            [-1, 8, 28, 28]               0\n",
            "       BatchNorm2d-3            [-1, 8, 28, 28]              16\n",
            "         Dropout2d-4            [-1, 8, 28, 28]               0\n",
            "            Conv2d-5            [-1, 8, 28, 28]             576\n",
            "              ReLU-6            [-1, 8, 28, 28]               0\n",
            "       BatchNorm2d-7            [-1, 8, 28, 28]              16\n",
            "         Dropout2d-8            [-1, 8, 28, 28]               0\n",
            "            Conv2d-9            [-1, 8, 28, 28]             576\n",
            "             ReLU-10            [-1, 8, 28, 28]               0\n",
            "      BatchNorm2d-11            [-1, 8, 28, 28]              16\n",
            "        Dropout2d-12            [-1, 8, 28, 28]               0\n",
            "        MaxPool2d-13            [-1, 8, 14, 14]               0\n",
            "           Conv2d-14           [-1, 12, 14, 14]              96\n",
            "           Conv2d-15           [-1, 12, 12, 12]           1,296\n",
            "             ReLU-16           [-1, 12, 12, 12]               0\n",
            "      BatchNorm2d-17           [-1, 12, 12, 12]              24\n",
            "        Dropout2d-18           [-1, 12, 12, 12]               0\n",
            "           Conv2d-19           [-1, 12, 10, 10]           1,296\n",
            "             ReLU-20           [-1, 12, 10, 10]               0\n",
            "      BatchNorm2d-21           [-1, 12, 10, 10]              24\n",
            "        Dropout2d-22           [-1, 12, 10, 10]               0\n",
            "           Conv2d-23             [-1, 12, 8, 8]           1,296\n",
            "             ReLU-24             [-1, 12, 8, 8]               0\n",
            "      BatchNorm2d-25             [-1, 12, 8, 8]              24\n",
            "        Dropout2d-26             [-1, 12, 8, 8]               0\n",
            "           Conv2d-27             [-1, 12, 6, 6]           1,296\n",
            "             ReLU-28             [-1, 12, 6, 6]               0\n",
            "      BatchNorm2d-29             [-1, 12, 6, 6]              24\n",
            "        Dropout2d-30             [-1, 12, 6, 6]               0\n",
            "           Conv2d-31             [-1, 12, 4, 4]           1,296\n",
            "             ReLU-32             [-1, 12, 4, 4]               0\n",
            "      BatchNorm2d-33             [-1, 12, 4, 4]              24\n",
            "        Dropout2d-34             [-1, 12, 4, 4]               0\n",
            "        MaxPool2d-35             [-1, 12, 2, 2]               0\n",
            "AdaptiveAvgPool2d-36             [-1, 12, 1, 1]               0\n",
            "           Conv2d-37             [-1, 10, 1, 1]             120\n",
            "================================================================\n",
            "Total params: 8,088\n",
            "Trainable params: 8,088\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.74\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.77\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:132: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "source": [
        "# SEED=1 so that we use the same random images for training, during each mini batch, during each epoch\n",
        "SEED=1\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "# download training data set: 50,000 images\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
        "\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "# download test data set: 10,000 images\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, y_target) in enumerate(pbar):\n",
        "    # get samples of 'batchsize'\n",
        "    data, y_target = data.to(device), y_target.to(device)\n",
        "\n",
        "    # So zero out the gradients before starting backpropragation because, without this, PyTorch accumulates gradients on subsequent backward passes. \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, y_target)     # negative log likelihood\n",
        "    train_losses.append(loss)\n",
        "    \n",
        "    loss.backward()  # do backpropagation across the graph:  dho(loss)/dho(weight)\n",
        "    optimizer.step() # adjust the weights\n",
        "\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max element\n",
        "    correct += pred.eq(y_target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Train phase: Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "  train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, y_target in test_loader:\n",
        "            data, y_target = data.to(device), y_target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, y_target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(y_target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print(f'\\nTest phase: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.2f}%)\\n')\n",
        "    \n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMWbLWO6FuHb",
        "outputId": "8e7a049f-5962-4143-d837-ca634b212a22"
      },
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        " \n",
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.04104, momentum=0.9)\n",
        "scheduler = StepLR(optimizer, step_size=2, gamma=0.09)   # after the specified 'step_size', scale(multiply) the current LR by the specified gamma..\n",
        " \n",
        "EPOCHS = 15\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"Epoch:\", epoch+1)\n",
        "    train(model, device, train_loader, optimizer)\n",
        "    test(model, device, test_loader)\n",
        "    if (epoch >= 8): scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:132: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "Train phase: Loss=0.16207543015480042 Batch_id=468 Accuracy=89.90: 100%|██████████| 469/469 [00:28<00:00, 16.48it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0614, Accuracy: 9812/10000 (98.12%)\n",
            "\n",
            "Epoch: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.08226000517606735 Batch_id=468 Accuracy=96.58: 100%|██████████| 469/469 [00:28<00:00, 16.47it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0460, Accuracy: 9860/10000 (98.60%)\n",
            "\n",
            "Epoch: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.050559911876916885 Batch_id=468 Accuracy=97.26: 100%|██████████| 469/469 [00:28<00:00, 16.57it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0356, Accuracy: 9895/10000 (98.95%)\n",
            "\n",
            "Epoch: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.09364146739244461 Batch_id=468 Accuracy=97.58: 100%|██████████| 469/469 [00:28<00:00, 16.73it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0331, Accuracy: 9908/10000 (99.08%)\n",
            "\n",
            "Epoch: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.12990759313106537 Batch_id=468 Accuracy=97.78: 100%|██████████| 469/469 [00:28<00:00, 16.62it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0314, Accuracy: 9897/10000 (98.97%)\n",
            "\n",
            "Epoch: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.02572879195213318 Batch_id=468 Accuracy=97.80: 100%|██████████| 469/469 [00:28<00:00, 16.71it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0301, Accuracy: 9917/10000 (99.17%)\n",
            "\n",
            "Epoch: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.081474669277668 Batch_id=468 Accuracy=98.10: 100%|██████████| 469/469 [00:28<00:00, 16.53it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0274, Accuracy: 9916/10000 (99.16%)\n",
            "\n",
            "Epoch: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.029412681236863136 Batch_id=468 Accuracy=98.11: 100%|██████████| 469/469 [00:28<00:00, 16.54it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0297, Accuracy: 9905/10000 (99.05%)\n",
            "\n",
            "Epoch: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.020261140540242195 Batch_id=468 Accuracy=98.19: 100%|██████████| 469/469 [00:28<00:00, 16.52it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0288, Accuracy: 9914/10000 (99.14%)\n",
            "\n",
            "Epoch: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.07269331067800522 Batch_id=468 Accuracy=98.24: 100%|██████████| 469/469 [00:28<00:00, 16.45it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0266, Accuracy: 9915/10000 (99.15%)\n",
            "\n",
            "Epoch: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.03265893831849098 Batch_id=468 Accuracy=98.49: 100%|██████████| 469/469 [00:28<00:00, 16.54it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0228, Accuracy: 9929/10000 (99.29%)\n",
            "\n",
            "Epoch: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.036436308175325394 Batch_id=468 Accuracy=98.59: 100%|██████████| 469/469 [00:28<00:00, 16.49it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0215, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "Epoch: 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.04511019587516785 Batch_id=468 Accuracy=98.73: 100%|██████████| 469/469 [00:28<00:00, 16.53it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0213, Accuracy: 9933/10000 (99.33%)\n",
            "\n",
            "Epoch: 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.031505391001701355 Batch_id=468 Accuracy=98.72: 100%|██████████| 469/469 [00:28<00:00, 16.47it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0214, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "Epoch: 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.06899045407772064 Batch_id=468 Accuracy=98.61: 100%|██████████| 469/469 [00:28<00:00, 16.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0215, Accuracy: 9933/10000 (99.33%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_accuracy(train_accuracy_list, test_accuracy_list):\n",
        "    fig, axs = plt.subplots(figsize=(5,5))\n",
        "    axs.plot(train_acc, label=\"Train Accuracy\")\n",
        "    axs.plot(test_acc, label=\"Test Accuracy\")\n",
        "    axs.legend()\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4fOu5ms0eaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe0e288-b68a-41db-985d-71f86ec3ee88"
      },
      "source": [
        "plot_accuracy(train_acc, test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wngdFkn_1b5a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}