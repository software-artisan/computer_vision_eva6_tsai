{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_5_8k_parameters_ver3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/software-artisan/computer_vision_eva6_tsai/blob/main/session_5_code_drill_down/assignment_5_8k_parameters_ver3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpPYe-KP0ESK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from collections import OrderedDict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        dropout=0.05\n",
        " \n",
        "        ####### \n",
        "        # Convolution Block #1\n",
        "        #########\n",
        "        self.conv1_1_3_3_8_p = nn.Sequential(OrderedDict([\n",
        "            ('conv1_1_3_3_8_p', nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=1, bias=False)),\n",
        "            ('relu', nn.ReLU()),\n",
        "            ('batchNorm2d', nn.BatchNorm2d(num_features=8)),\n",
        "            ('dropOut2d', nn.Dropout2d(p=dropout))\n",
        "          ])\n",
        "        ) # Input=28, Output=28, rf=3\n",
        "\n",
        "        self.conv2_8_3_3_8_p = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=8),\n",
        "            nn.Dropout2d(p=dropout)\n",
        "        ) # Input=28, Output=28, rf=5\n",
        " \n",
        "        self.conv3_8_3_3_8_p = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=8),\n",
        "            nn.Dropout2d(p=dropout) \n",
        "        ) # Input=28, Output=28, rf=10\n",
        " \n",
        "        ####### \n",
        "        # Transition Block #1\n",
        "        #########\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2) # Input=28, Output=14, rf=6\n",
        " \n",
        "        # self.conv4_8_1_1_16 = nn.Sequential(\n",
        "        #     #nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=0, bias=False),\n",
        "        #     nn.Conv2d(in_channels=8, out_channels=12, kernel_size=1, padding=0, bias=False),\n",
        "        # ) # Input=14, Output=14, rf=32\n",
        " \n",
        "        ####### \n",
        "        # Convolution Block #2\n",
        "        #########\n",
        "        self.conv5_12_3_3_12 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=12, kernel_size=3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=12),\n",
        "            nn.Dropout2d(p=dropout)\n",
        "        ) # Input=14, Output=12, rf=14\n",
        " \n",
        "        self.conv6_12_3_3_12 = nn.Sequential(\n",
        "            #nn.Conv2d(in_channels=14, out_channels=14, kernel_size=3, padding=0, bias=False),\n",
        "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=12),\n",
        "            nn.Dropout2d(p=dropout) # Input=12, Output=10, rf=24\n",
        "        )\n",
        "        \n",
        "        self.conv7_12_3_3_12 = nn.Sequential(\n",
        "            #nn.Conv2d(in_channels=14, out_channels=14, kernel_size=3, padding=0, bias=False),\n",
        "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=12),\n",
        "            nn.Dropout2d(p=dropout) # Input=10, Output=8, rf=24\n",
        "        )\n",
        "        \n",
        "        self.conv8_12_3_3_12 = nn.Sequential(\n",
        "            #nn.Conv2d(in_channels=14, out_channels=14, kernel_size=3, padding=0, bias=False),\n",
        "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=12),\n",
        "            nn.Dropout2d(p=dropout) \n",
        "        ) # Input=8, Output=6, rf=24\n",
        "\n",
        "        self.conv9_12_3_3_12 = nn.Sequential(\n",
        "            #nn.Conv2d(in_channels=14, out_channels=14, kernel_size=3, padding=0, bias=False),\n",
        "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=12),\n",
        "            #nn.Dropout2d(p=dropout) \n",
        "        ) # Input=6, Output=4, rf=24\n",
        "        \n",
        "        self.maxpool2= nn.MaxPool2d(kernel_size=2, stride=2) # Input=4, Output=2, rf=16\n",
        " \n",
        "        ####### \n",
        "        # Output Block\n",
        "        #########\n",
        "        # global average pool before 1x1 to reduce computation\n",
        "        self.global_avgpool = nn.AdaptiveAvgPool2d(output_size=1)  # Input=5, Output=1, rf=40\n",
        " \n",
        "        self.conv10_16_1_1_10 = nn.Sequential(\n",
        "            #nn.Conv2d(in_channels=14, out_channels=10, kernel_size=3, padding=0, bias=False),\n",
        "            nn.Conv2d(in_channels=12, out_channels=10, kernel_size=1, padding=0, bias=False),\n",
        "        ) # Input=1, Output=1, rf=32\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #####\n",
        "        # conv block #1\n",
        "        ########\n",
        "        x = self.conv1_1_3_3_8_p(x)\n",
        "        x = self.conv2_8_3_3_8_p(x)\n",
        "        x = self.conv3_8_3_3_8_p(x)\n",
        " \n",
        "        #####\n",
        "        # Transitioni block #1\n",
        "        ########\n",
        "        x = self.maxpool1(x)\n",
        "        #x = self.conv4_8_1_1_16(x)\n",
        " \n",
        "        #####\n",
        "        # conv block #2\n",
        "        ########\n",
        "        x = self.conv5_12_3_3_12(x)\n",
        "        x = self.conv6_12_3_3_12(x)\n",
        "        x = self.conv7_12_3_3_12(x)\n",
        "        x = self.conv8_12_3_3_12(x)\n",
        "        x = self.conv9_12_3_3_12(x)\n",
        "\n",
        "        #######\n",
        "        # Transition block #2\n",
        "        #######\n",
        "        x = self.maxpool2(x)\n",
        " \n",
        "        #####\n",
        "        # output block\n",
        "        ########\n",
        "        x = self.global_avgpool(x)        \n",
        "        x = self.conv10_16_1_1_10(x)\n",
        "               \n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdydjYTZFyi3",
        "outputId": "fd4385cb-df7d-43c4-e7d1-f866d3e6a5ea"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              72\n",
            "              ReLU-2            [-1, 8, 28, 28]               0\n",
            "       BatchNorm2d-3            [-1, 8, 28, 28]              16\n",
            "         Dropout2d-4            [-1, 8, 28, 28]               0\n",
            "            Conv2d-5            [-1, 8, 28, 28]             576\n",
            "              ReLU-6            [-1, 8, 28, 28]               0\n",
            "       BatchNorm2d-7            [-1, 8, 28, 28]              16\n",
            "         Dropout2d-8            [-1, 8, 28, 28]               0\n",
            "            Conv2d-9            [-1, 8, 28, 28]             576\n",
            "             ReLU-10            [-1, 8, 28, 28]               0\n",
            "      BatchNorm2d-11            [-1, 8, 28, 28]              16\n",
            "        Dropout2d-12            [-1, 8, 28, 28]               0\n",
            "        MaxPool2d-13            [-1, 8, 14, 14]               0\n",
            "           Conv2d-14           [-1, 12, 12, 12]             864\n",
            "             ReLU-15           [-1, 12, 12, 12]               0\n",
            "      BatchNorm2d-16           [-1, 12, 12, 12]              24\n",
            "        Dropout2d-17           [-1, 12, 12, 12]               0\n",
            "           Conv2d-18           [-1, 12, 10, 10]           1,296\n",
            "             ReLU-19           [-1, 12, 10, 10]               0\n",
            "      BatchNorm2d-20           [-1, 12, 10, 10]              24\n",
            "        Dropout2d-21           [-1, 12, 10, 10]               0\n",
            "           Conv2d-22             [-1, 12, 8, 8]           1,296\n",
            "             ReLU-23             [-1, 12, 8, 8]               0\n",
            "      BatchNorm2d-24             [-1, 12, 8, 8]              24\n",
            "        Dropout2d-25             [-1, 12, 8, 8]               0\n",
            "           Conv2d-26             [-1, 12, 6, 6]           1,296\n",
            "             ReLU-27             [-1, 12, 6, 6]               0\n",
            "      BatchNorm2d-28             [-1, 12, 6, 6]              24\n",
            "        Dropout2d-29             [-1, 12, 6, 6]               0\n",
            "           Conv2d-30             [-1, 12, 4, 4]           1,296\n",
            "             ReLU-31             [-1, 12, 4, 4]               0\n",
            "      BatchNorm2d-32             [-1, 12, 4, 4]              24\n",
            "        MaxPool2d-33             [-1, 12, 2, 2]               0\n",
            "AdaptiveAvgPool2d-34             [-1, 12, 1, 1]               0\n",
            "           Conv2d-35             [-1, 10, 1, 1]             120\n",
            "================================================================\n",
            "Total params: 7,560\n",
            "Trainable params: 7,560\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.72\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.75\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:132: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "source": [
        "# SEED=1 so that we use the same random images for training, during each mini batch, during each epoch\n",
        "SEED=1\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "# download training data set: 50,000 images\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
        "\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "# download test data set: 10,000 images\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, y_target) in enumerate(pbar):\n",
        "    # get samples of 'batchsize'\n",
        "    data, y_target = data.to(device), y_target.to(device)\n",
        "\n",
        "    # So zero out the gradients before starting backpropragation because, without this, PyTorch accumulates gradients on subsequent backward passes. \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, y_target)     # negative log likelihood\n",
        "    train_losses.append(loss)\n",
        "    \n",
        "    loss.backward()  # do backpropagation across the graph:  dho(loss)/dho(weight)\n",
        "    optimizer.step() # adjust the weights\n",
        "\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max element\n",
        "    correct += pred.eq(y_target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Train phase: Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "  train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, y_target in test_loader:\n",
        "            data, y_target = data.to(device), y_target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, y_target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(y_target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print(f'\\nTest phase: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.2f}%)\\n')\n",
        "    \n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMWbLWO6FuHb",
        "outputId": "9665c137-26c0-466a-9413-4a2efc534e72"
      },
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        " \n",
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.04104, momentum=0.9)\n",
        "scheduler = StepLR(optimizer, step_size=2, gamma=0.2)   # after the specified 'step_size', scale(multiply) the current LR by the specified gamma..\n",
        " \n",
        "EPOCHS = 15\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"Epoch:\", epoch+1)\n",
        "    train(model, device, train_loader, optimizer)\n",
        "    test(model, device, test_loader)\n",
        "    if (epoch >= 8): scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:132: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "Train phase: Loss=0.17949408292770386 Batch_id=468 Accuracy=91.67: 100%|██████████| 469/469 [00:17<00:00, 26.65it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0547, Accuracy: 9832/10000 (98.32%)\n",
            "\n",
            "Epoch: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.08025898039340973 Batch_id=468 Accuracy=97.04: 100%|██████████| 469/469 [00:17<00:00, 26.77it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0396, Accuracy: 9877/10000 (98.77%)\n",
            "\n",
            "Epoch: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.04209919646382332 Batch_id=468 Accuracy=97.60: 100%|██████████| 469/469 [00:17<00:00, 26.86it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0298, Accuracy: 9907/10000 (99.07%)\n",
            "\n",
            "Epoch: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.08606193214654922 Batch_id=468 Accuracy=97.93: 100%|██████████| 469/469 [00:17<00:00, 26.58it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0280, Accuracy: 9910/10000 (99.10%)\n",
            "\n",
            "Epoch: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.01165237557142973 Batch_id=468 Accuracy=98.10: 100%|██████████| 469/469 [00:17<00:00, 27.11it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0264, Accuracy: 9926/10000 (99.26%)\n",
            "\n",
            "Epoch: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.03690127283334732 Batch_id=468 Accuracy=98.11: 100%|██████████| 469/469 [00:17<00:00, 26.85it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0271, Accuracy: 9910/10000 (99.10%)\n",
            "\n",
            "Epoch: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.026127420365810394 Batch_id=468 Accuracy=98.38: 100%|██████████| 469/469 [00:17<00:00, 26.37it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0255, Accuracy: 9921/10000 (99.21%)\n",
            "\n",
            "Epoch: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.16056539118289948 Batch_id=468 Accuracy=98.34: 100%|██████████| 469/469 [00:17<00:00, 26.54it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0252, Accuracy: 9921/10000 (99.21%)\n",
            "\n",
            "Epoch: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.034272562712430954 Batch_id=468 Accuracy=98.40: 100%|██████████| 469/469 [00:17<00:00, 26.15it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0216, Accuracy: 9931/10000 (99.31%)\n",
            "\n",
            "Epoch: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.0855652317404747 Batch_id=468 Accuracy=98.48: 100%|██████████| 469/469 [00:17<00:00, 26.29it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0261, Accuracy: 9916/10000 (99.16%)\n",
            "\n",
            "Epoch: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.015207829885184765 Batch_id=468 Accuracy=98.67: 100%|██████████| 469/469 [00:17<00:00, 26.18it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0198, Accuracy: 9946/10000 (99.46%)\n",
            "\n",
            "Epoch: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.03666846081614494 Batch_id=468 Accuracy=98.78: 100%|██████████| 469/469 [00:18<00:00, 25.74it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0189, Accuracy: 9944/10000 (99.44%)\n",
            "\n",
            "Epoch: 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.022886531427502632 Batch_id=468 Accuracy=98.81: 100%|██████████| 469/469 [00:17<00:00, 26.19it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0183, Accuracy: 9944/10000 (99.44%)\n",
            "\n",
            "Epoch: 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.007360551971942186 Batch_id=468 Accuracy=98.93: 100%|██████████| 469/469 [00:17<00:00, 26.20it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0183, Accuracy: 9946/10000 (99.46%)\n",
            "\n",
            "Epoch: 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train phase: Loss=0.035941511392593384 Batch_id=468 Accuracy=98.88: 100%|██████████| 469/469 [00:17<00:00, 26.06it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test phase: Average loss: 0.0180, Accuracy: 9944/10000 (99.44%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_accuracy(train_accuracy_list, test_accuracy_list):\n",
        "    fig, axs = plt.subplots(figsize=(5,5))\n",
        "    axs.plot(train_acc, label=\"Train Accuracy\")\n",
        "    axs.plot(test_acc, label=\"Test Accuracy\")\n",
        "    axs.legend()\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4fOu5ms0eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "9a42bca3-0d57-4692-8f01-2589ed417568"
      },
      "source": [
        "plot_accuracy(train_acc, test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wngdFkn_1b5a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}